{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-GmAOkq5D7M_",
    "outputId": "b1c9ac7a-aa7a-4899-bfde-b8646fade408"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: XlsxWriter in /usr/local/lib/python3.7/dist-packages (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install XlsxWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U4hFDlcSDwjV",
    "outputId": "e06fe33c-8f7f-42ed-e414-643303e9bbba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "SHObboSHDlgS"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import xlsxwriter\n",
    "import PIL\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fCk7K0QzCXVs"
   },
   "source": [
    "Unzip dataset file. Just need to do it one time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4_X-0RiC9VgZ",
    "outputId": "2f9454f4-c96e-4366-b329-f5404fd1d50d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /content/drive/MyDrive/img_align_celeba.zip\n",
      "replace /content/drive/MyDrive/train/001/001000.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
     ]
    }
   ],
   "source": [
    "!unzip '/content/drive/MyDrive/img_align_celeba.zip' -d '/content/drive/MyDrive/train/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3scwrcouChcK"
   },
   "source": [
    "Make models.\n",
    "1. Generator: four deconvolution layers with 5x5 kernel, and strides for 2x2. They are all followed by a batch normalization and leakyReLU.\n",
    "2. Discriminator: three convolution layers with 5x5 kernel, and strides for 2x2. They are followed by a leakyReLU. And, the last two convolution layers will dropout for 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "5WplyRhAYbP8"
   },
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "  model = tf.keras.Sequential()\n",
    "  model.add(layers.Dense((256 * 8 * 8), input_shape=(100,)))\n",
    "  model.add(layers.BatchNormalization())\n",
    "  model.add(layers.LeakyReLU())\n",
    "  \n",
    "  model.add(layers.Reshape((8, 8, 256)))\n",
    "  assert model.output_shape == (None, 8, 8, 256)  # Note: None is the batch size\n",
    "\n",
    "  model.add(layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "  model.add(layers.BatchNormalization())\n",
    "  model.add(layers.LeakyReLU())\n",
    "\n",
    "  model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "  model.add(layers.BatchNormalization())\n",
    "  model.add(layers.LeakyReLU())\n",
    "\n",
    "  model.add(layers.Conv2DTranspose(32, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "  model.add(layers.BatchNormalization())\n",
    "  model.add(layers.LeakyReLU())\n",
    "\n",
    "  model.add(layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', activation='tanh', use_bias=False))\n",
    "\n",
    "  return model\n",
    "\n",
    "def make_discriminator_model():\n",
    "  model = tf.keras.Sequential()\n",
    "  model.add(layers.Input(shape=(128, 128, 3)))\n",
    "  model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same'))\n",
    "  model.add(layers.LeakyReLU())\n",
    "\n",
    "  model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "  model.add(layers.LeakyReLU())\n",
    "  model.add(layers.Dropout(0.5))\n",
    "\n",
    "  model.add(layers.Conv2D(256, (5, 5), strides=(2, 2), padding='same'))\n",
    "  model.add(layers.LeakyReLU())\n",
    "  model.add(layers.Dropout(0.5))\n",
    "\n",
    "  model.add(layers.Flatten())\n",
    "  model.add(layers.Dense(1))\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "umjZEvHAh_3C",
    "outputId": "6506aed9-137e-432a-dd87-8d9cc0d7bd7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 16384)             1654784   \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 16384)            65536     \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 16384)             0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 16, 16, 128)      819200    \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16, 16, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 32, 32, 64)       204800    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 32, 32, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 64, 64, 32)       51200     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 64, 64, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 64, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2DT  (None, 128, 128, 3)      2400      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,798,816\n",
      "Trainable params: 2,765,600\n",
      "Non-trainable params: 33,216\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 64, 64, 64)        4864      \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 64, 64, 64)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 128)       204928    \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 256)       819456    \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 65536)             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65537     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,094,785\n",
      "Trainable params: 1,094,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = make_generator_model()\n",
    "generator.summary()\n",
    "discriminator = make_discriminator_model()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dx2a7mV4DRup"
   },
   "source": [
    "Both generator and discriminator use Adam optimizers with learning rate 0.0002\n",
    "\n",
    "Last function is Binary Cross Entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Lg128EZ1zujG"
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "generator_optimizer = tf.keras.optimizers.Adam(0.0002)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(0.0002)\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "  return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "  real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "  fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "  total_loss = real_loss + fake_loss\n",
    "  return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "56BJqcjNDnjT"
   },
   "source": [
    "Loading checkpoint. This part is used for continuing training process.\n",
    "\n",
    "You can change the storing location at checkpoint_dir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R8qpbDy8zlcH",
    "outputId": "720ff590-3e00-4e13-a58a-a850cc0d1a9a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f33fd5c3d10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_dir = 'drive/MyDrive/train/DCGAN_check'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                  discriminator_optimizer=discriminator_optimizer,\n",
    "                  generator=generator,\n",
    "                  discriminator=discriminator)\n",
    "manager = tf.train.CheckpointManager(checkpoint, checkpoint_prefix, max_to_keep=5)\n",
    "checkpoint.restore(manager.latest_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJ0tydjODxt2"
   },
   "source": [
    "Loading Dataset. Those images will be cropped into 128x128 colored images.\n",
    "\n",
    "Batch size is 256.\n",
    "\n",
    "The first parameter of image_dataset_from_directory is the location of the dataset folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oQuDluuxeqZg",
    "outputId": "f35f995c-dcc7-43e1-fd32-fd60ef811782"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2460 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 256\n",
    "\n",
    "all_images = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    'drive/MyDrive/img_align_celeba/',\n",
    "    batch_size=1,\n",
    "    image_size=(218,178),\n",
    "    shuffle=True,\n",
    "    labels=None\n",
    ")\n",
    "\n",
    "def process(image):\n",
    "  image = tf.reshape(image, [1, 218, 178, 3])\n",
    "  image = tf.image.crop_and_resize(image, [[0.14, 0.205, 0.86, 0.795]], [0], [128, 128])\n",
    "  image = tf.cast((image-127.5) / 127.5 ,tf.float32)\n",
    "  return image\n",
    "\n",
    "all_images = all_images.map(process)\n",
    "all_images = all_images.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_WJ3EooQEQhQ"
   },
   "source": [
    "Training process.\n",
    "\n",
    "It will automatically random;y pick and store the generator and discriminator loss, and also a real and generated image every 10 batchs.\n",
    "\n",
    "You can change the folder location using the parameter of save_result function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "GtuVkLlfxSao"
   },
   "outputs": [],
   "source": [
    "noise_dim = 100\n",
    "\n",
    "@tf.function\n",
    "def train_step(real_images, current_batch_size):\n",
    "  noise = tf.random.normal([current_batch_size, noise_dim])\n",
    "\n",
    "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "    generated_images = generator(noise, training=True)\n",
    "\n",
    "    real_output = discriminator(real_images, training=True)\n",
    "    fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "    gen_loss = generator_loss(fake_output)\n",
    "    disc_loss = discriminator_loss(real_output, fake_output)\n",
    "  \n",
    "  gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "  generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "  gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "  discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "  return gen_loss, disc_loss, real_images, generated_images, fake_output\n",
    "\n",
    "\n",
    "def train(dataset, epochs, last_epoch):\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    recent_epoch = epoch + last_epoch + 1\n",
    "    data = []\n",
    "    real_images = []\n",
    "    generated_images = []\n",
    "    batch_num = 0\n",
    "    print('Start training for epoch {}'.format(recent_epoch))\n",
    "\n",
    "    for images in dataset:\n",
    "      current_batch_size = images.shape[0]\n",
    "      images = tf.reshape(images, [current_batch_size, images.shape[2], images.shape[3], images.shape[4]])\n",
    "      \n",
    "      gen_loss, disc_loss, real_image, generated_image, fake_output = train_step(images, current_batch_size)\n",
    "      batch_num += 1\n",
    "      if (batch_num % 10) == 0:\n",
    "        r = np.random.randint(current_batch_size)\n",
    "        data.append((gen_loss.numpy(), disc_loss.numpy(), fake_output.numpy()[r]))\n",
    "        real_images.append(real_image.numpy()[r])\n",
    "        generated_images.append(generated_image.numpy()[r])\n",
    "        print('Batch {} training finished'.format(batch_num))\n",
    "    \n",
    "    if (recent_epoch % 5) == 0:\n",
    "      manager.save()\n",
    "\n",
    "    save_result(data, real_images, generated_images, recent_epoch, 'drive/MyDrive/train/DCGAN_result')\n",
    "    display.clear_output(wait=True)\n",
    "    print ('Time for epoch {} is {} sec'.format(recent_epoch, time.time()-start))\n",
    "    print ('generator loss:', gen_loss.numpy())\n",
    "    print ('disciminator loss:', disc_loss.numpy())\n",
    "\n",
    "\n",
    "def save_result(data, real_images, generated_images, epoch_num, loc):\n",
    "  wb = xlsxwriter.Workbook(f'{loc}/epoch{epoch_num:03}.xlsx')\n",
    "  os.makedirs(f'{loc}/epoch{epoch_num:03}/real', exist_ok=True)\n",
    "  os.makedirs(f'{loc}/epoch{epoch_num:03}/generated', exist_ok=True)\n",
    "  ws = wb.add_worksheet()\n",
    "  ws.write_row(0, 0, ('Batch Index', 'Generator Loss', 'Discriminator Loss', 'Generated Image Prediction'))\n",
    "  batch_num = 1\n",
    "  for result, real_img, gene_img in zip(data, real_images, generated_images):\n",
    "    ws.write_row(batch_num, 0, (batch_num, result[0], result[1], result[2]))\n",
    "    save_img = (real_img * 127.5 + 127.5)\n",
    "    save_img = PIL.Image.fromarray(np.uint8(save_img))\n",
    "    save_img.save(f'{loc}/epoch{epoch_num:03}/real/{batch_num:03}.png') \n",
    "    save_img = (gene_img * 127.5 + 127.5)\n",
    "    save_img = PIL.Image.fromarray(np.uint8(save_img))\n",
    "    save_img.save(f'{loc}/epoch{epoch_num:03}/generated/{batch_num:03}.png')\n",
    "    batch_num += 1\n",
    "  wb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "__U_A-_3Y8Dv",
    "outputId": "32128519-81be-4824-de04-868312fbece4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch 100 is 15.572921991348267 sec\n",
      "generator loss: 4.296874\n",
      "disciminator loss: 0.14261913\n"
     ]
    }
   ],
   "source": [
    "train(all_images, 100, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XKtZK_EBSBKf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "DCGAN_baseline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
